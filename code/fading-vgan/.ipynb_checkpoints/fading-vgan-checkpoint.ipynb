{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Fading Channel Distribution\n",
    "\n",
    "Generate a (siimplistic) distribution representative of a fading channel:\n",
    "\n",
    "$y=\\alpha x(t)$\n",
    "\n",
    "Where $\\alpha$ is a r.v. taken from an arbitrary distribution that describes the nature of the fading while $x(t)$ is a random variable describing the symbols to-be-transmitted.\n",
    "\n",
    "In this case, we will take Bernoulli $x(t)\\in [-1,1]$ and Uniform $\\alpha \\thicksim \\mathcal{U}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import bernoulli, uniform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# params\n",
    "T = 1000\n",
    "p = 0.5\n",
    "# sample from bernoulli distribution to get bspk vals [-1,1]\n",
    "x = bernoulli.rvs(p, size=T)\n",
    "x = np.array([1 if x[i] == 1 else -1 for i in range(len(x))])\n",
    "\n",
    "# get indices of respective r.v. vals\n",
    "i_hi=np.argwhere(x==1)\n",
    "i_lo=np.argwhere(x==-1)\n",
    "\n",
    "# sample from uniform distribution\n",
    "# -> default [0,1] - can change params if fading characteristics need to be different\n",
    "alpha = uniform.rvs(size=T) \n",
    "\n",
    "# generate fading channel data\n",
    "y=np.multiply(alpha,x)\n",
    "\n",
    "# plot histogram of distribution from hi/lo BPSK samples\n",
    "bins=np.linspace(-1,1,100)\n",
    "plt.hist(y[i_hi], bins=bins,density=True)  \n",
    "plt.hist(y[i_lo], bins=bins,density=True) \n",
    "plt.title(\"Fading Channel Sample Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN\n",
    "\n",
    "Based on code from [Keras-GAN repo](https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py), build variational GAN and train on fading channel samples from previous cell. *Need to change parameters and architecture based on O'Shea paper*.\n",
    "\n",
    "Notes from [O'Shea paper](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_OShea_ApproximatingTheVoidVariationalGANS.pdf):\n",
    " - Adam optimizer with learning rate $\\alpha \\in$ [1e-4,5e-4]\n",
    " - ![Parameters for GAN](https://drive.google.com/uc?export=view&id=1mPIxaTNVb-tNEK0e2cqzldb-CDIGs3BH)\n",
    "\n",
    "Questions:\n",
    "  - Latent vars in GAN variational layer are mean/variance of different Gaussian distributions? (16 samplers w/ 32 params)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-24aa5ad97c88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "#         optimizer = RMSprop(lr=0.00005)\n",
    "        optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # here's where we build the generator; need following [Layer, Output #]\n",
    "#         FC-RelU 20\n",
    "#         FC-RelU 20\n",
    "#         FC-RelU 20\n",
    "#         FC-Lin  32\n",
    "#         Sampler 16\n",
    "#         FC-RelU 80\n",
    "#         FC-Lin  2\n",
    "        \n",
    "        # new code\n",
    "  \n",
    "        # original code\n",
    "#         model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "#         model.add(Reshape((7, 7, 128)))\n",
    "#         model.add(UpSampling2D())\n",
    "#         model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(UpSampling2D())\n",
    "#         model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "#         model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                \n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the critic\n",
    "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                # Clip critic weights\n",
    "                for l in self.critic.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=4000, batch_size=32, sample_interval=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
